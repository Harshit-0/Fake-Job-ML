{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "abed093c-95de-4087-ac32-4c4fbc48db6a",
   "metadata": {},
   "source": [
    "# üß† Fake Job Posting Detection using NLP + ML\n",
    "Detect fraudulent job postings using text classification with TF-IDF and ML algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c5e45e-c6b2-4c7f-b880-ee475f4a711d",
   "metadata": {},
   "source": [
    "## üì¶ Load Dataset & Import Libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0268f304-d1ef-4b5c-a5f0-831387acecfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "df = pd.read_csv(\"fake_job_postings.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e6c7d4-6dbd-4bfd-8e45-10e17a997ff2",
   "metadata": {},
   "source": [
    "## üîç Explore Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce8c7c29-a937-4e74-9c7c-b065e6985858",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape:\", df.shape)\n",
    "df.info()\n",
    "print(\"\\nTarget Value Counts:\\n\", df['fraudulent'].value_counts())\n",
    "\n",
    "sns.countplot(x='fraudulent', data=df)\n",
    "plt.title(\"Fake vs Real Job Postings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14cca7e1-fc9b-44ca-b710-6222cb53d1a9",
   "metadata": {},
   "source": [
    "## üßπ Clean the Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6fee4d-cdd1-4a7c-aa53-aeeb51fdf790",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"job_id\", \"salary_range\", \"telecommuting\", \"has_company_logo\", \n",
    "                      \"has_questions\", \"employment_type\", \"required_experience\", \n",
    "                      \"required_education\", \"industry\", \"function\"], errors='ignore')\n",
    "\n",
    "df = df.dropna(subset=['description'])\n",
    "\n",
    "text_cols = ['title', 'company_profile', 'description', 'requirements', 'benefits']\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].fillna('')\n",
    "\n",
    "df['text'] = df['title'] + \" \" + df['company_profile'] + \" \" + df['description'] + \" \" + df['requirements'] + \" \" + df['benefits']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a8681-18f1-47ee-a5b8-8fe9add090c3",
   "metadata": {},
   "source": [
    "## üßº Clean the Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7f9d0-6209-4a00-9aff-c6ee3a634328",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    tokens = text.split()\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['clean_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826a6fa7-d06c-491f-9f37-fb2f16fa2a0c",
   "metadata": {},
   "source": [
    "## ‚ú® Vectorize Text using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2302436c-240f-4d94-b515-0c1a0580ef38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X = tfidf.fit_transform(df['clean_text']).toarray()\n",
    "y = df['fraudulent']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da671bf7-4ddc-4edc-8184-2bf6e4e5262b",
   "metadata": {},
   "source": [
    "## üîÄ Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a592c6c-a279-4542-9c1f-0aaf95b0fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a8966-721b-41bb-bec6-f0cb81b1ee66",
   "metadata": {},
   "source": [
    "## ü§ñ Train Machine Learning Models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28062fbb-1b2d-4efd-a64c-90e18143a77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=100),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f6b9d7-65f9-4f72-b1f3-b6d8040ad53b",
   "metadata": {},
   "source": [
    "## üìà Evaluate the Best Model (ROC & AUC)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfa988d-d0bd-4392-9e83-ba8161708382",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models['Random Forest']\n",
    "y_proba = best_model.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.plot(fpr, tpr, label='ROC Curve')\n",
    "plt.plot([0,1], [0,1], linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"AUC Score:\", roc_auc_score(y_test, y_proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ec7489-58c4-431f-a107-e11735593306",
   "metadata": {},
   "source": [
    "## üíæ Save the Trained Model and Vectorizer using joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80824aa0-d852-4117-803c-c37081e69d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, \"fake_job_model.pkl\")\n",
    "\n",
    "# Save the vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c297614b-5437-4d76-a30b-f82ebbf466f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e8870-b3f5-4aef-9b0f-a3ae370783eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
